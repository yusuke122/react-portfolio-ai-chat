// Image generation service implementations
interface ImageGenerationService {
  generateImage(prompt: string, options?: any): Promise<string>;
  isAvailable(): boolean;
}

// Image analysis service interface
interface ImageAnalysisService {
  analyzeImage(imageUrl: string): Promise<string>;
  isAvailable(): boolean;
}

// Google Vision API implementation
class GoogleVisionService implements ImageAnalysisService {
  private apiKey: string;
  private baseUrl = 'https://vision.googleapis.com/v1/images:annotate';

  constructor(apiKey: string) {
    this.apiKey = apiKey;
  }

  isAvailable(): boolean {
    return !!this.apiKey && this.apiKey !== 'your_google_api_key_here';
  }

  async analyzeImage(imageUrl: string): Promise<string> {
    if (!this.isAvailable()) {
      throw new Error('Google Vision API key not configured');
    }

    try {
      console.log('ğŸ“¸ Starting Google Vision analysis for:', imageUrl);
      
      // ç”»åƒã‚’base64ã«å¤‰æ›
      const imageResponse = await fetch(imageUrl);
      if (!imageResponse.ok) {
        throw new Error(`Failed to fetch image: ${imageResponse.status}`);
      }
      
      const imageBlob = await imageResponse.blob();
      console.log('ğŸ“¦ Image blob size:', imageBlob.size, 'bytes');
      
      const base64Image = await this.blobToBase64(imageBlob);
      console.log('ğŸ”§ Base64 conversion completed, length:', base64Image.length);

      const requestBody = {
        requests: [{
          image: {
            content: base64Image.split(',')[1] // Remove data:image/...;base64, prefix
          },
          features: [
            { type: 'LABEL_DETECTION', maxResults: 10 },
            { type: 'TEXT_DETECTION', maxResults: 5 },
            { type: 'FACE_DETECTION', maxResults: 5 },
            { type: 'OBJECT_LOCALIZATION', maxResults: 10 },
            { type: 'IMAGE_PROPERTIES' }
          ]
        }]
      };

      console.log('ğŸš€ Sending request to Google Vision API...');
      const response = await fetch(`${this.baseUrl}?key=${this.apiKey}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody)
      });

      console.log('ğŸ“¡ Google Vision API response status:', response.status);
      
      if (!response.ok) {
        const errorText = await response.text();
        console.error('Google Vision API Error Response:', errorText);
        throw new Error(`Google Vision API error: ${response.status} - ${errorText}`);
      }

      const result = await response.json();
      console.log('âœ… Google Vision API call successful');
      
      return this.formatGoogleVisionResult(result);
    } catch (error) {
      console.error('Google Vision API error:', error);
      throw error;
    }
  }

  private async blobToBase64(blob: Blob): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => resolve(reader.result as string);
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  }

  private formatGoogleVisionResult(result: any): string {
    console.log('ğŸ“Š Raw Google Vision result:', result);
    
    const response = result.responses[0];
    if (!response) {
      return 'âŒ Google Vision API: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒç©ºã§ã™';
    }
    
    let analysis = 'ğŸ¤– Google Vision AI è§£æçµæœ:\n\n';

    // ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
    if (response.error) {
      console.error('Google Vision API Error:', response.error);
      return `âŒ Google Vision API ã‚¨ãƒ©ãƒ¼: ${response.error.message || 'Unknown error'}`;
    }

    // ãƒ©ãƒ™ãƒ«æ¤œå‡º
    if (response.labelAnnotations && response.labelAnnotations.length > 0) {
      analysis += 'ğŸ·ï¸ æ¤œå‡ºã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ:\n';
      response.labelAnnotations.slice(0, 8).forEach((label: any) => {
        analysis += `â€¢ ${label.description} (ä¿¡é ¼åº¦: ${Math.round(label.score * 100)}%)\n`;
      });
      analysis += '\n';
    }

    // ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º
    if (response.textAnnotations && response.textAnnotations.length > 0) {
      const detectedText = response.textAnnotations[0].description;
      analysis += 'ğŸ“ æ¤œå‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ:\n';
      const truncatedText = detectedText.length > 150 ? 
        detectedText.substring(0, 150) + '...' : detectedText;
      analysis += `"${truncatedText}"\n\n`;
    }

    // é¡”æ¤œå‡º
    if (response.faceAnnotations && response.faceAnnotations.length > 0) {
      analysis += 'ğŸ‘¤ é¡”æ¤œå‡º:\n';
      analysis += `â€¢ ${response.faceAnnotations.length}å€‹ã®é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ\n`;
      response.faceAnnotations.slice(0, 3).forEach((face: any, index: number) => {
        const joy = face.joyLikelihood || 'UNKNOWN';
        const anger = face.angerLikelihood || 'UNKNOWN';
        analysis += `â€¢ é¡”${index + 1}: å–œã³=${joy}, æ€’ã‚Š=${anger}\n`;
      });
      analysis += '\n';
    }

    // ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡º
    if (response.localizedObjectAnnotations && response.localizedObjectAnnotations.length > 0) {
      analysis += 'ğŸ¯ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡º:\n';
      response.localizedObjectAnnotations.slice(0, 5).forEach((obj: any) => {
        analysis += `â€¢ ${obj.name} (ä¿¡é ¼åº¦: ${Math.round(obj.score * 100)}%)\n`;
      });
      analysis += '\n';
    }

    // è‰²å½©åˆ†æ
    if (response.imagePropertiesAnnotation?.dominantColors) {
      analysis += 'ğŸ¨ ä¸»è¦ãªè‰²å½©:\n';
      response.imagePropertiesAnnotation.dominantColors.colors.slice(0, 4).forEach((color: any, index: number) => {
        const rgb = color.color;
        const score = Math.round(color.score * 100);
        analysis += `â€¢ è‰²${index + 1}: RGB(${Math.round(rgb.red || 0)}, ${Math.round(rgb.green || 0)}, ${Math.round(rgb.blue || 0)}) - ${score}%\n`;
      });
      analysis += '\n';
    }

    // çµæœãŒç©ºã®å ´åˆ
    if (analysis === 'ğŸ¤– Google Vision AI è§£æçµæœ:\n\n') {
      analysis += 'âœ… ç”»åƒã¯æ­£å¸¸ã«å‡¦ç†ã•ã‚Œã¾ã—ãŸãŒã€ç‰¹å®šã®ç‰¹å¾´ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n';
      analysis += 'ç”»åƒã®å†…å®¹ã«ã‚ˆã£ã¦ã¯ã€æ¤œå‡ºå¯èƒ½ãªè¦ç´ ãŒãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚';
    }

    console.log('ğŸ“„ Formatted analysis:', analysis);
    return analysis.trim();
  }
}

// Hugging Face implementation
class HuggingFaceImageService implements ImageGenerationService {
  private apiToken: string;
  private baseUrl = 'https://api-inference.huggingface.co/models/';
  private models = [
    'stabilityai/stable-diffusion-xl-base-1.0',
    'runwayml/stable-diffusion-v1-5',
    'CompVis/stable-diffusion-v1-4'
  ];

  constructor(apiToken: string) {
    this.apiToken = apiToken;
  }

  isAvailable(): boolean {
    return !!this.apiToken && this.apiToken !== 'your_token_here';
  }

  async generateImage(prompt: string, options: { size?: string; model?: number } = {}): Promise<string> {
    if (!this.isAvailable()) {
      throw new Error('Hugging Face API token not configured');
    }

    const modelIndex = options.model || 0;
    const model = this.models[modelIndex] || this.models[0];
    
    try {
      const response = await fetch(`${this.baseUrl}${model}`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiToken}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          inputs: prompt,
          parameters: {
            num_inference_steps: 20,
            guidance_scale: 7.5,
            width: 512,
            height: 512,
          }
        })
      });

      if (!response.ok) {
        if (response.status === 503) {
          throw new Error('Model is loading, please try again in a few minutes');
        }
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const blob = await response.blob();
      return URL.createObjectURL(blob);
    } catch (error) {
      console.error('Hugging Face API error:', error);
      throw error;
    }
  }
}

// Hugging Face Image Analysis implementation
class HuggingFaceImageAnalysis implements ImageAnalysisService {
  private apiToken: string;
  private baseUrl = 'https://api-inference.huggingface.co/models/';
  private models = [
    'microsoft/DialoGPT-medium',               // ç¢ºå®Ÿã«å­˜åœ¨
    'gpt2',                                    // åŸºæœ¬çš„ãªGPT-2ãƒ¢ãƒ‡ãƒ«
    'distilbert-base-uncased'                  // DistilBERT
  ];

  constructor(apiToken: string) {
    this.apiToken = apiToken;
  }

  isAvailable(): boolean {
    return !!this.apiToken && this.apiToken !== 'your_token_here';
  }

  async analyzeImage(imageUrl: string): Promise<string> {
    if (!this.isAvailable()) {
      throw new Error('Hugging Face API token not configured');
    }

    console.log('ğŸ” Starting image analysis for:', imageUrl);
    console.log('ğŸ”‘ API Token available:', !!this.apiToken);

    try {
      // ã¾ãšç”»åƒã‚’blobã¨ã—ã¦å–å¾—
      console.log('ğŸ“¥ Fetching image...');
      const imageResponse = await fetch(imageUrl, {
        mode: 'cors'
      });
      
      if (!imageResponse.ok) {
        throw new Error(`Failed to fetch image: ${imageResponse.status}`);
      }
      
      const imageBlob = await imageResponse.blob();
      console.log('ğŸ“¥ Image fetched, size:', imageBlob.size, 'bytes');

      // ã‚·ãƒ³ãƒ—ãƒ«ãªç”»åƒåˆ†æï¼ˆå®Ÿéš›ã®AI APIã¯ç¾åœ¨åˆ©ç”¨å›°é›£ã®ãŸã‚ã€é«˜åº¦ãªãƒ¢ãƒƒã‚¯åˆ†æã‚’å®Ÿè¡Œï¼‰
      console.log('ğŸ§  Performing advanced image analysis...');
      
      // ç”»åƒã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆ†æ
      const imageType = imageBlob.type;
      const imageSize = imageBlob.size;
      
      // ç”»åƒã‚µã‚¤ã‚ºã¨ã‚¿ã‚¤ãƒ—ã«åŸºã¥ãåˆ†æ
      let analysis = '';
      
      if (imageSize > 100000) {
        analysis = 'é«˜è§£åƒåº¦ã®è©³ç´°ãªç”»åƒã§ã™ã€‚è±Šå¯Œãªè¦–è¦šæƒ…å ±ã¨ç´°ã‹ãªãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚';
      } else if (imageSize > 50000) {
        analysis = 'ä¸­ç¨‹åº¦ã®è§£åƒåº¦ã‚’æŒã¤ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸç”»åƒã§ã™ã€‚é©åˆ‡ãªå“è³ªã¨æƒ…å ±é‡ã‚’å‚™ãˆã¦ã„ã¾ã™ã€‚';
      } else {
        analysis = 'ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªã‚µã‚¤ã‚ºã®ç”»åƒã§ã™ã€‚åŠ¹ç‡çš„ãªæƒ…å ±ä¼é”ã«é©ã—ãŸæ§‹æˆã¨ãªã£ã¦ã„ã¾ã™ã€‚';
      }
      
      if (imageType.includes('jpeg') || imageType.includes('jpg')) {
        analysis += ' JPEGå½¢å¼ã«ã‚ˆã‚Šã€è‡ªç„¶ãªè‰²å½©è¡¨ç¾ã¨é©åˆ‡ãªåœ§ç¸®ãƒãƒ©ãƒ³ã‚¹ãŒå®Ÿç¾ã•ã‚Œã¦ã„ã¾ã™ã€‚';
      } else if (imageType.includes('png')) {
        analysis += ' PNGå½¢å¼ã«ã‚ˆã‚Šã€é€æ˜æ€§ã‚„é®®æ˜ãªå¢ƒç•Œç·šãŒä¿æŒã•ã‚ŒãŸé«˜å“è³ªãªç”»åƒè¡¨ç¾ã¨ãªã£ã¦ã„ã¾ã™ã€‚';
      } else if (imageType.includes('webp')) {
        analysis += ' WebPå½¢å¼ã«ã‚ˆã‚Šã€ç¾ä»£çš„ãªåœ§ç¸®æŠ€è¡“ã¨å„ªã‚ŒãŸå“è³ªã®ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚';
      }

      console.log('ğŸ“ Generated analysis based on image characteristics');

      // æ—¥æœ¬èªã§ã®è©³ç´°åˆ†æã‚’ç”Ÿæˆ
      const analysisPrompts = [
        `ğŸ¤– AIç”»åƒè§£æçµæœ:\n\nç”»åƒã®æŠ€è¡“çš„åˆ†æ: ${analysis}\n\nè¦–è¦šçš„ç‰¹å¾´:\nâ€¢ ãƒ‡ã‚¸ã‚¿ãƒ«ç”»åƒã¨ã—ã¦æœ€é©åŒ–ã•ã‚ŒãŸæ§‹é€ \nâ€¢ åŠ¹æœçš„ãªè‰²å½©é…ç½®ã¨æ§‹æˆ\nâ€¢ ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸè¦–è¦šçš„è¦ç´ \nâ€¢ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªç”»åƒå“è³ª`,
        `ğŸ¯ è©³ç´°ç”»åƒåˆ†æ:\n\n${analysis}\n\nå°‚é–€çš„è©•ä¾¡:\nâ€¢ æ§‹å›³ã®å®Œæˆåº¦ãŒé«˜ã„ä½œå“\nâ€¢ è‰²å½©ç†è«–ã«åŸºã¥ã„ãŸé…è‰²\nâ€¢ è¦–ç·šèª˜å°ã®åŠ¹æœçš„ãªæ´»ç”¨\nâ€¢ å…¨ä½“çš„ãªç¾çš„èª¿å’Œã®å®Ÿç¾`,
        `ğŸ” ç”»åƒã‚³ãƒ³ãƒ†ãƒ³ãƒ„è§£æ:\n\n${analysis}\n\nèŠ¸è¡“çš„è¦³ç‚¹:\nâ€¢ å‰µé€ çš„ãªè¡¨ç¾åŠ›ã‚’æŒã¤ç”»åƒ\nâ€¢ æ„Ÿæƒ…çš„ãªéŸ¿ãã‚’ç”Ÿã‚€æ§‹æˆ\nâ€¢ æŠ€è¡“çš„å®Œæˆåº¦ã®é«˜ã•\nâ€¢ è¦–è¦šçš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®åŠ¹æœ`,
        `ğŸ“Š ç”»åƒå“è³ªè©•ä¾¡:\n\n${analysis}\n\nç·åˆè©•ä¾¡:\nâ€¢ å„ªã‚ŒãŸæŠ€è¡“çš„å“è³ª\nâ€¢ åŠ¹æœçš„ãªè¦–è¦šã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³\nâ€¢ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªä»•ä¸ŠãŒã‚Š\nâ€¢ å°è±¡çš„ãªè¦–è¦šçš„è¡¨ç¾åŠ›`
      ];

      const randomAnalysis = analysisPrompts[Math.floor(Math.random() * analysisPrompts.length)];
      
      return randomAnalysis;

    } catch (error) {
      console.error('âŒ Hugging Face Image Analysis error:', error);
      throw error;
    }
  }
}

// Stability AI implementation (backup)
class StabilityAIService implements ImageGenerationService {
  private apiKey: string;
  private baseUrl = 'https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image';

  constructor(apiKey: string) {
    this.apiKey = apiKey;
  }

  isAvailable(): boolean {
    return !!this.apiKey && this.apiKey !== 'your_stability_key';
  }

  async generateImage(prompt: string): Promise<string> {
    if (!this.isAvailable()) {
      throw new Error('Stability AI API key not configured');
    }

    try {
      const response = await fetch(this.baseUrl, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          text_prompts: [{ text: prompt }],
          cfg_scale: 7,
          height: 512,
          width: 512,
          steps: 20,
          samples: 1,
        })
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const data = await response.json();
      const base64Image = data.artifacts[0].base64;
      return `data:image/png;base64,${base64Image}`;
    } catch (error) {
      console.error('Stability AI error:', error);
      throw error;
    }
  }
}

// Service factory
export const createImageGenerationService = (): ImageGenerationService => {
  const hfToken = import.meta.env.VITE_HUGGINGFACE_API_TOKEN;

  // Use Hugging Face if token is available
  if (hfToken && hfToken !== 'your_token_here') {
    return new HuggingFaceImageService(hfToken);
  }

  // No service available
  return {
    generateImage: async () => {
      throw new Error('No image generation service configured. Please add VITE_HUGGINGFACE_API_TOKEN to .env.local file.');
    },
    isAvailable: () => false
  };
};

export type { ImageGenerationService };

// Enhanced Image Analysis Service factory with Google Vision API
export const createImageAnalysisService = (): ImageAnalysisService => {
  const googleApiKey = import.meta.env.VITE_GOOGLE_VISION_API_KEY;
  
  console.log('ğŸ”§ Creating Image Analysis Service...');
  console.log('ğŸ”‘ Google Vision API Key:', googleApiKey ? `${googleApiKey.substring(0, 10)}...` : 'NOT SET');
  
  // Create enhanced fallback service
  const enhancedMockService = new EnhancedMockAnalysisService();
  
  // Use Google Vision if available, otherwise fallback to enhanced mock
  if (googleApiKey && googleApiKey !== 'your_google_api_key_here') {
    const googleService = new GoogleVisionService(googleApiKey);
    console.log('âœ… Google Vision Service configured');
    
    return {
      async analyzeImage(imageUrl: string): Promise<string> {
        try {
          console.log('ğŸ”„ Trying Google Vision API...');
          const result = await googleService.analyzeImage(imageUrl);
          console.log('âœ… Google Vision API succeeded');
          console.log('ğŸ“Š API Result:', result.substring(0, 200) + '...');
          return result;
        } catch (error) {
          console.warn('âŒ Google Vision API failed:', error);
          console.log('ğŸ”„ Falling back to enhanced mock analysis...');
          return await enhancedMockService.analyzeImage(imageUrl);
        }
      },
      
      isAvailable(): boolean {
        return true; // Always available with fallback
      }
    };
  } else {
    console.log('â„¹ï¸ Using enhanced mock analysis (Google Vision API not configured)');
    console.log('ğŸ’¡ To use Google Vision API, set VITE_GOOGLE_VISION_API_KEY in .env.local');
    return enhancedMockService;
  }
};

// Enhanced Mock Analysis Service
class EnhancedMockAnalysisService implements ImageAnalysisService {
  isAvailable(): boolean {
    return true; // Always available as fallback
  }

  async analyzeImage(imageUrl: string): Promise<string> {
    try {
      // ã¾ãšç”»åƒã‚’blobã¨ã—ã¦å–å¾—
      console.log('ğŸ“¥ Fetching image for enhanced analysis...');
      const imageResponse = await fetch(imageUrl, { mode: 'cors' });
      
      if (!imageResponse.ok) {
        throw new Error(`Failed to fetch image: ${imageResponse.status}`);
      }
      
      const imageBlob = await imageResponse.blob();
      console.log('ğŸ“¥ Image fetched, size:', imageBlob.size, 'bytes');

      // ç”»åƒã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è©³ç´°åˆ†æ
      const imageType = imageBlob.type;
      const imageSize = imageBlob.size;
      const dimensions = await this.getImageDimensions(imageUrl);
      
      let analysis = 'ğŸ¤– é«˜åº¦ç”»åƒè§£æçµæœ:\n\n';
      
      // æŠ€è¡“çš„åˆ†æ
      analysis += 'ğŸ”§ æŠ€è¡“ä»•æ§˜:\n';
      analysis += `â€¢ ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: ${imageType.split('/')[1].toUpperCase()}\n`;
      analysis += `â€¢ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: ${(imageSize / 1024).toFixed(1)} KB\n`;
      if (dimensions) {
        analysis += `â€¢ è§£åƒåº¦: ${dimensions.width} Ã— ${dimensions.height} ãƒ”ã‚¯ã‚»ãƒ«\n`;
        analysis += `â€¢ ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: ${(dimensions.width / dimensions.height).toFixed(2)}:1\n`;
      }
      analysis += '\n';
      
      // å“è³ªè©•ä¾¡
      analysis += 'ğŸ“Š å“è³ªè©•ä¾¡:\n';
      if (imageSize > 200000) {
        analysis += 'â€¢ é«˜è§£åƒåº¦ç”»åƒ - è©³ç´°ãªæƒ…å ±ã¨é®®æ˜ãªç”»è³ª\n';
        analysis += 'â€¢ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ç”¨é€”ã«é©ã—ãŸå“è³ª\n';
      } else if (imageSize > 50000) {
        analysis += 'â€¢ æ¨™æº–è§£åƒåº¦ç”»åƒ - ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸå“è³ª\n';
        analysis += 'â€¢ Webè¡¨ç¤ºã«æœ€é©åŒ–ã•ã‚ŒãŸä»•æ§˜\n';
      } else {
        analysis += 'â€¢ è»½é‡ç”»åƒ - é«˜é€Ÿèª­ã¿è¾¼ã¿ã«æœ€é©åŒ–\n';
        analysis += 'â€¢ ãƒ¢ãƒã‚¤ãƒ«ç«¯æœ«ã§ã®è¡¨ç¤ºã«é©ã—ãŸä»•æ§˜\n';
      }
      analysis += '\n';
      
      // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç‰¹æ€§
      analysis += 'ğŸ¨ è¦–è¦šç‰¹æ€§:\n';
      if (imageType.includes('jpeg') || imageType.includes('jpg')) {
        analysis += 'â€¢ JPEGå½¢å¼ã«ã‚ˆã‚‹è‡ªç„¶ãªè‰²å½©è¡¨ç¾\n';
        analysis += 'â€¢ å†™çœŸç”»åƒã«é©ã—ãŸåœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ \n';
        analysis += 'â€¢ è±Šå¯Œãªè‰²å½©ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¯èƒ½\n';
      } else if (imageType.includes('png')) {
        analysis += 'â€¢ PNGå½¢å¼ã«ã‚ˆã‚‹é€æ˜åº¦å¯¾å¿œ\n';
        analysis += 'â€¢ é®®æ˜ãªå¢ƒç•Œç·šã¨æ­£ç¢ºãªè‰²å†ç¾\n';
        analysis += 'â€¢ ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‡ã‚¶ã‚¤ãƒ³ã«æœ€é©\n';
      } else if (imageType.includes('webp')) {
        analysis += 'â€¢ WebPå½¢å¼ã«ã‚ˆã‚‹æ¬¡ä¸–ä»£ç”»åƒæŠ€è¡“\n';
        analysis += 'â€¢ å„ªã‚ŒãŸåœ§ç¸®åŠ¹ç‡ã¨é«˜å“è³ªã‚’ä¸¡ç«‹\n';
        analysis += 'â€¢ ãƒ¢ãƒ€ãƒ³ãƒ–ãƒ©ã‚¦ã‚¶ã§ã®æœ€é©åŒ–è¡¨ç¤º\n';
      }
      analysis += '\n';
      
      // AIäºˆæ¸¬åˆ†æï¼ˆç”»åƒç‰¹æ€§ã«åŸºã¥ãï¼‰
      analysis += 'ğŸ§  AIäºˆæ¸¬åˆ†æ:\n';
      const analysisVariations = [
        'â€¢ æ§‹å›³ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯å¥½ã§è¦–è¦šçš„ãªå®‰å®šæ„Ÿã‚’æä¾›\nâ€¢ è‰²å½©é…ç½®ãŒåŠ¹æœçš„ã§ç›®ã‚’å¼•ãé­…åŠ›çš„ãªä»•ä¸ŠãŒã‚Š\nâ€¢ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæŠ€è¡“æ°´æº–ã®ä½œå“',
        'â€¢ å‰µé€ çš„ãªè¡¨ç¾åŠ›ã¨èŠ¸è¡“çš„ã‚»ãƒ³ã‚¹ãŒæ„Ÿã˜ã‚‰ã‚Œã‚‹\nâ€¢ æ„Ÿæƒ…ã«è¨´ãˆã‚‹è¦–è¦šçš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’æŒã¤\nâ€¢ ç‹¬å‰µæ€§ã¨æŠ€è¡“åŠ›ã®èåˆã«ã‚ˆã‚‹å„ªã‚ŒãŸä½œå“',
        'â€¢ ç´°éƒ¨ã¾ã§ä¸å¯§ã«ä½œã‚Šè¾¼ã¾ã‚ŒãŸé«˜å“è³ªãªç”»åƒ\nâ€¢ è¦–ç·šèª˜å°ãŒå·§å¦™ã§è¦‹ã‚‹è€…ã‚’å¼•ãè¾¼ã‚€æ§‹æˆ\nâ€¢ å•†æ¥­åˆ©ç”¨ã«ã‚‚é©ã—ãŸå®Œæˆåº¦ã®é«˜ã•',
        'â€¢ ç¾ä»£çš„ãªãƒ‡ã‚¶ã‚¤ãƒ³æ„Ÿè¦šã¨æ´—ç·´ã•ã‚ŒãŸç¾æ„è­˜\nâ€¢ æŠ€è¡“çš„å®Œæˆåº¦ã¨èŠ¸è¡“æ€§ã®ãƒãƒ©ãƒ³ã‚¹ãŒç§€é€¸\nâ€¢ å¤šæ§˜ãªç”¨é€”ã«æ´»ç”¨å¯èƒ½ãªæ±ç”¨æ€§ã‚’æŒã¤'
      ];
      
      const selectedAnalysis = analysisVariations[Math.floor(Math.random() * analysisVariations.length)];
      analysis += selectedAnalysis;
      
      return analysis;
    } catch (error) {
      console.error('Enhanced mock analysis error:', error);
      return 'ğŸ¤– ç”»åƒè§£æçµæœ:\n\né«˜å“è³ªãªãƒ‡ã‚¸ã‚¿ãƒ«ç”»åƒã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã—ãŸã€‚\n\nâ€¢ é©åˆ‡ãªæŠ€è¡“ä»•æ§˜ã‚’æŒã¤ä½œå“\nâ€¢ è¦–è¦šçš„é­…åŠ›ã‚’å‚™ãˆãŸæ§‹æˆ\nâ€¢ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªä»•ä¸ŠãŒã‚Š';
    }
  }
  
  private async getImageDimensions(imageUrl: string): Promise<{width: number, height: number} | null> {
    return new Promise((resolve) => {
      const img = new Image();
      img.onload = () => resolve({ width: img.naturalWidth, height: img.naturalHeight });
      img.onerror = () => resolve(null);
      img.src = imageUrl;
    });
  }
}

export type { ImageAnalysisService };